{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load & check the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    6  148  72  35    0  33.6  0.627  50  1\n",
      "0   1   85  66  29    0  26.6  0.351  31  0\n",
      "1   8  183  64   0    0  23.3  0.672  32  1\n",
      "2   1   89  66  23   94  28.1  0.167  21  0\n",
      "3   0  137  40  35  168  43.1  2.288  33  1\n",
      "4   5  116  74   0    0  25.6  0.201  30  0\n",
      "5   3   78  50  32   88  31.0  0.248  26  1\n",
      "6  10  115   0   0    0  35.3  0.134  29  0\n",
      "7   2  197  70  45  543  30.5  0.158  53  1\n",
      "8   8  125  96   0    0   0.0  0.232  54  1\n",
      "9   4  110  92   0    0  37.6  0.191  30  0\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            1       85             66             29        0  26.6   \n",
      "1            8      183             64              0        0  23.3   \n",
      "2            1       89             66             23       94  28.1   \n",
      "3            0      137             40             35      168  43.1   \n",
      "4            5      116             74              0        0  25.6   \n",
      "5            3       78             50             32       88  31.0   \n",
      "6           10      115              0              0        0  35.3   \n",
      "7            2      197             70             45      543  30.5   \n",
      "8            8      125             96              0        0   0.0   \n",
      "9            4      110             92              0        0  37.6   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.351   31        0  \n",
      "1                     0.672   32        1  \n",
      "2                     0.167   21        0  \n",
      "3                     2.288   33        1  \n",
      "4                     0.201   30        0  \n",
      "5                     0.248   26        1  \n",
      "6                     0.134   29        0  \n",
      "7                     0.158   53        1  \n",
      "8                     0.232   54        1  \n",
      "9                     0.191   30        0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_renee = pd.read_csv('pima-indians-diabetes.csv')\n",
    "first_10_rows = df_renee.head(10)\n",
    "print(first_10_rows)\n",
    "# step of 2: Add the column names i.e. add a header record to the data frame\n",
    "df_renee.columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'] \n",
    "print(df_renee.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carryout some initial investigations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies                   int64\n",
      "Glucose                       int64\n",
      "BloodPressure                 int64\n",
      "SkinThickness                 int64\n",
      "Insulin                       int64\n",
      "BMI                         float64\n",
      "DiabetesPedigreeFunction    float64\n",
      "Age                           int64\n",
      "Outcome                       int64\n",
      "dtype: object\n",
      "Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "Insulin                     0\n",
      "BMI                         0\n",
      "DiabetesPedigreeFunction    0\n",
      "Age                         0\n",
      "Outcome                     0\n",
      "dtype: int64\n",
      "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
      "count   767.000000  767.000000     767.000000     767.000000  767.000000   \n",
      "mean      3.842243  120.859192      69.101695      20.517601   79.903520   \n",
      "std       3.370877   31.978468      19.368155      15.954059  115.283105   \n",
      "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
      "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
      "50%       3.000000  117.000000      72.000000      23.000000   32.000000   \n",
      "75%       6.000000  140.000000      80.000000      32.000000  127.500000   \n",
      "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
      "\n",
      "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
      "count  767.000000                767.000000  767.000000  767.000000  \n",
      "mean    31.990482                  0.471674   33.219035    0.348110  \n",
      "std      7.889091                  0.331497   11.752296    0.476682  \n",
      "min      0.000000                  0.078000   21.000000    0.000000  \n",
      "25%     27.300000                  0.243500   24.000000    0.000000  \n",
      "50%     32.000000                  0.371000   29.000000    0.000000  \n",
      "75%     36.600000                  0.625000   41.000000    1.000000  \n",
      "max     67.100000                  2.420000   81.000000    1.000000  \n",
      "Outcome\n",
      "0    500\n",
      "1    267\n",
      "Name: count, dtype: int64\n",
      "Outcome\n",
      "0    500\n",
      "1    267\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the names and types of columns.\n",
    "print(df_renee.dtypes)\n",
    "# Check the missing values.\n",
    "print(df_renee.isnull().sum())\n",
    "# Check the statistics of the numeric fields (mean, min, max, median, count,..etc.)\n",
    "print(df_renee.describe())\n",
    "# Check the categorical values, if any.\n",
    "print(df_renee['Outcome'].value_counts())\n",
    "\n",
    "###########In you written response write a paragraph explaining your findings about each column.###########\n",
    "# Print out the total number of instances in each class\n",
    "print(df_renee['Outcome'].value_counts())\n",
    "\n",
    "##########and note into your report and explain your findings in terms of balanced and un-balanced classes.##########\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process and prepare the data for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a standard scaler transformer to transform all the numeric values. \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "transformer_renee = StandardScaler()\n",
    "# Split the features from the class.\n",
    "X = df_renee.drop('Outcome', axis=1)\n",
    "y = df_renee['Outcome']\n",
    "# Split your data into train 70% train and 30% test, use 42 for the seed. Name the train/test dataframes as follows : X_train_firstname, X_test firstname, y_train firstname, y_test firstname\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_renee, X_test_renee, y_train_renee, y_test_renee = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# Apply(fit, transform the transformer prepared in step 4 to the features i.e. X_train_firstname, X_test firstname, Name the transformer transformer_firstname, (Note: You might need to work on some transformation for the labels in order for the classifiers to work properly)\n",
    "transformer_renee.fit(X_train_renee)\n",
    "X_train_renee = transformer_renee.transform(X_train_renee)\n",
    "X_test_renee = transformer_renee.transform(X_test_renee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise #1 :Hard voting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n",
      "LogisticRegression [0 0 0] 667    0\n",
      "324    0\n",
      "623    0\n",
      "Name: Outcome, dtype: int64\n",
      "RandomForestClassifier [0 0 0] 667    0\n",
      "324    0\n",
      "623    0\n",
      "Name: Outcome, dtype: int64\n",
      "SVC [0 0 0] 667    0\n",
      "324    0\n",
      "623    0\n",
      "Name: Outcome, dtype: int64\n",
      "DecisionTreeClassifier [1 0 0] 667    0\n",
      "324    0\n",
      "623    0\n",
      "Name: Outcome, dtype: int64\n",
      "ExtraTreesClassifier [0 0 0] 667    0\n",
      "324    0\n",
      "623    0\n",
      "Name: Outcome, dtype: int64\n",
      "VotingClassifier [0 0 0] 667    0\n",
      "324    0\n",
      "623    0\n",
      "Name: Outcome, dtype: int64\n",
      "LogisticRegression\n",
      "0.7922077922077922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       151\n",
      "           1       0.77      0.57      0.66        80\n",
      "\n",
      "    accuracy                           0.79       231\n",
      "   macro avg       0.78      0.74      0.75       231\n",
      "weighted avg       0.79      0.79      0.78       231\n",
      "\n",
      "[[137  14]\n",
      " [ 34  46]]\n",
      "----------------------------------\n",
      "RandomForestClassifier\n",
      "0.7619047619047619\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       151\n",
      "           1       0.66      0.64      0.65        80\n",
      "\n",
      "    accuracy                           0.76       231\n",
      "   macro avg       0.74      0.73      0.73       231\n",
      "weighted avg       0.76      0.76      0.76       231\n",
      "\n",
      "[[125  26]\n",
      " [ 29  51]]\n",
      "----------------------------------\n",
      "SVC\n",
      "0.7532467532467533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       151\n",
      "           1       0.68      0.55      0.61        80\n",
      "\n",
      "    accuracy                           0.75       231\n",
      "   macro avg       0.73      0.71      0.71       231\n",
      "weighted avg       0.75      0.75      0.75       231\n",
      "\n",
      "[[130  21]\n",
      " [ 36  44]]\n",
      "----------------------------------\n",
      "DecisionTreeClassifier\n",
      "0.696969696969697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76       151\n",
      "           1       0.55      0.65      0.60        80\n",
      "\n",
      "    accuracy                           0.70       231\n",
      "   macro avg       0.67      0.69      0.68       231\n",
      "weighted avg       0.71      0.70      0.70       231\n",
      "\n",
      "[[109  42]\n",
      " [ 28  52]]\n",
      "----------------------------------\n",
      "ExtraTreesClassifier\n",
      "0.7792207792207793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       151\n",
      "           1       0.72      0.59      0.65        80\n",
      "\n",
      "    accuracy                           0.78       231\n",
      "   macro avg       0.76      0.73      0.74       231\n",
      "weighted avg       0.77      0.78      0.77       231\n",
      "\n",
      "[[133  18]\n",
      " [ 33  47]]\n",
      "----------------------------------\n",
      "VotingClassifier\n",
      "0.7748917748917749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       151\n",
      "           1       0.71      0.60      0.65        80\n",
      "\n",
      "    accuracy                           0.77       231\n",
      "   macro avg       0.75      0.73      0.74       231\n",
      "weighted avg       0.77      0.77      0.77       231\n",
      "\n",
      "[[131  20]\n",
      " [ 32  48]]\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# step #8: Define 5 classifiers & give them names of your choice, just add at the end _X, where X is the first letter of your last name. Details of classifiers are as follows:\n",
    "# a. Logistic Regression set max_iter=1400\n",
    "# b. Random Forest Classifier, use the defaults\n",
    "# c. Support vector machines use the defaults\n",
    "# d. Decision Tree Classifier set criterion=\"entropy\" & max_depth =42\n",
    "# e. Extra Trees Classifier, use the defaults\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "logistic_regression_v = LogisticRegression(max_iter=1400)\n",
    "random_forest_v = RandomForestClassifier()\n",
    "svc_v = SVC()\n",
    "decision_tree_v = DecisionTreeClassifier(criterion='entropy', max_depth=42)\n",
    "extra_trees_v = ExtraTreesClassifier()\n",
    "\n",
    "# Define a voting classifier that contains all the above classifiers as estimators, set the voting to hard\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_classifier_v = VotingClassifier(estimators=[('lr', logistic_regression_v), ('rf', random_forest_v), ('svc', svc_v), ('dt', decision_tree_v), ('et', extra_trees_v)], voting='hard')\n",
    "# Fit the training data to the voting classifier and predict the first three instances of test data\n",
    "voting_classifier_v.fit(X_train_renee, y_train_renee)\n",
    "y_pred_v = voting_classifier_v.predict(X_test_renee)\n",
    "print(y_pred_v[:3])\n",
    "# bu using a nested loop, Print out for each classifier (including the voting classifier) and for each instance the predicted and the actual values and note them in your written response.\n",
    "for clf in (logistic_regression_v, random_forest_v, svc_v, decision_tree_v, extra_trees_v, voting_classifier_v):\n",
    "    clf.fit(X_train_renee, y_train_renee)\n",
    "    y_pred = clf.predict(X_test_renee)\n",
    "    print(clf.__class__.__name__, y_pred[:3], y_test_renee[:3])\n",
    "\n",
    "# Print out the accuracy score, classification report, and confusion matrix for each classifier and the voting classifier.\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "for clf in (logistic_regression_v, random_forest_v, svc_v, decision_tree_v, extra_trees_v, voting_classifier_v):\n",
    "    clf.fit(X_train_renee, y_train_renee)\n",
    "    y_pred = clf.predict(X_test_renee)\n",
    "    print(clf.__class__.__name__)\n",
    "    print(accuracy_score(y_test_renee, y_pred))\n",
    "    print(classification_report(y_test_renee, y_pred))\n",
    "    print(confusion_matrix(y_test_renee, y_pred))\n",
    "    print('----------------------------------')\n",
    "\n",
    "###########In your written response, analyze the results and draw some conclusions about the performance of the classifiers.###########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise #2: Soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n",
      "LogisticRegression [0 0 0] 667    0\n",
      "324    0\n",
      "623    0\n",
      "Name: Outcome, dtype: int64\n",
      "RandomForestClassifier [0 0 0] 667    0\n",
      "324    0\n",
      "623    0\n",
      "Name: Outcome, dtype: int64\n",
      "SVC [0 0 0] 667    0\n",
      "324    0\n",
      "623    0\n",
      "Name: Outcome, dtype: int64\n",
      "DecisionTreeClassifier [1 0 0] 667    0\n",
      "324    0\n",
      "623    0\n",
      "Name: Outcome, dtype: int64\n",
      "ExtraTreesClassifier [0 0 0] 667    0\n",
      "324    0\n",
      "623    0\n",
      "Name: Outcome, dtype: int64\n",
      "VotingClassifier [0 0 0] 667    0\n",
      "324    0\n",
      "623    0\n",
      "Name: Outcome, dtype: int64\n",
      "LogisticRegression\n",
      "0.7922077922077922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       151\n",
      "           1       0.77      0.57      0.66        80\n",
      "\n",
      "    accuracy                           0.79       231\n",
      "   macro avg       0.78      0.74      0.75       231\n",
      "weighted avg       0.79      0.79      0.78       231\n",
      "\n",
      "[[137  14]\n",
      " [ 34  46]]\n",
      "----------------------------------\n",
      "RandomForestClassifier\n",
      "0.7489177489177489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81       151\n",
      "           1       0.65      0.60      0.62        80\n",
      "\n",
      "    accuracy                           0.75       231\n",
      "   macro avg       0.72      0.71      0.72       231\n",
      "weighted avg       0.75      0.75      0.75       231\n",
      "\n",
      "[[125  26]\n",
      " [ 32  48]]\n",
      "----------------------------------\n",
      "SVC\n",
      "0.7532467532467533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       151\n",
      "           1       0.68      0.55      0.61        80\n",
      "\n",
      "    accuracy                           0.75       231\n",
      "   macro avg       0.73      0.71      0.71       231\n",
      "weighted avg       0.75      0.75      0.75       231\n",
      "\n",
      "[[130  21]\n",
      " [ 36  44]]\n",
      "----------------------------------\n",
      "DecisionTreeClassifier\n",
      "0.6926406926406926\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76       151\n",
      "           1       0.55      0.61      0.58        80\n",
      "\n",
      "    accuracy                           0.69       231\n",
      "   macro avg       0.67      0.67      0.67       231\n",
      "weighted avg       0.70      0.69      0.70       231\n",
      "\n",
      "[[111  40]\n",
      " [ 31  49]]\n",
      "----------------------------------\n",
      "ExtraTreesClassifier\n",
      "0.7532467532467533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82       151\n",
      "           1       0.66      0.60      0.63        80\n",
      "\n",
      "    accuracy                           0.75       231\n",
      "   macro avg       0.73      0.72      0.72       231\n",
      "weighted avg       0.75      0.75      0.75       231\n",
      "\n",
      "[[126  25]\n",
      " [ 32  48]]\n",
      "----------------------------------\n",
      "VotingClassifier\n",
      "0.7532467532467533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82       151\n",
      "           1       0.66      0.60      0.63        80\n",
      "\n",
      "    accuracy                           0.75       231\n",
      "   macro avg       0.73      0.72      0.72       231\n",
      "weighted avg       0.75      0.75      0.75       231\n",
      "\n",
      "[[126  25]\n",
      " [ 32  48]]\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Repeat al the section Exercise #1 :Hard voting, except this step: \"Define a voting classifier that contains all the above classifiers as estimators, set the voting to hard.\", Note: You might need to change some classifiers defaults.\n",
    "logistic_regression_v = LogisticRegression(max_iter=1400)\n",
    "random_forest_v = RandomForestClassifier()\n",
    "svc_v = SVC(probability=True)\n",
    "decision_tree_v = DecisionTreeClassifier(criterion='entropy', max_depth=42)\n",
    "extra_trees_v = ExtraTreesClassifier()\n",
    "# Define a voting classifier that contains all the above classifiers as estimators, set the voting to soft\n",
    "voting_classifier_v = VotingClassifier(estimators=[('lr', logistic_regression_v), ('rf', random_forest_v), ('svc', svc_v), ('dt', decision_tree_v), ('et', extra_trees_v)], voting='soft')\n",
    "# Fit the training data to the voting classifier and predict the first three instances of test data\n",
    "voting_classifier_v.fit(X_train_renee, y_train_renee)\n",
    "y_pred_v = voting_classifier_v.predict(X_test_renee)\n",
    "print(y_pred_v[:3])\n",
    "# bu using a nested loop, Print out for each classifier (including the voting classifier) and for each instance the predicted and the actual values and note them in your written response.\n",
    "for clf in (logistic_regression_v, random_forest_v, svc_v, decision_tree_v, extra_trees_v, voting_classifier_v):\n",
    "    clf.fit(X_train_renee, y_train_renee)\n",
    "    y_pred = clf.predict(X_test_renee)\n",
    "    print(clf.__class__.__name__, y_pred[:3], y_test_renee[:3])\n",
    "\n",
    "# Print out the accuracy score, classification report, and confusion matrix for each classifier and the voting classifier.\n",
    "for clf in (logistic_regression_v, random_forest_v, svc_v, decision_tree_v, extra_trees_v, voting_classifier_v):\n",
    "    clf.fit(X_train_renee, y_train_renee)\n",
    "    y_pred = clf.predict(X_test_renee)\n",
    "    print(clf.__class__.__name__)\n",
    "    print(accuracy_score(y_test_renee, y_pred))\n",
    "    print(classification_report(y_test_renee, y_pred))\n",
    "    print(confusion_matrix(y_test_renee, y_pred))\n",
    "    print('----------------------------------')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise #3: Random forests & Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7516072676450034\n",
      "0.6919636617749825\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('et', ExtraTreesClassifier())])\n",
      "[[129  22]\n",
      " [ 35  45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       151\n",
      "           1       0.67      0.56      0.61        80\n",
      "\n",
      "    accuracy                           0.75       231\n",
      "   macro avg       0.73      0.71      0.72       231\n",
      "weighted avg       0.75      0.75      0.75       231\n",
      "\n",
      "0.7532467532467533\n",
      "----------------------------------\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('dt',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=42))])\n",
      "[[113  38]\n",
      " [ 29  51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.77       151\n",
      "           1       0.57      0.64      0.60        80\n",
      "\n",
      "    accuracy                           0.71       231\n",
      "   macro avg       0.68      0.69      0.69       231\n",
      "weighted avg       0.72      0.71      0.71       231\n",
      "\n",
      "0.70995670995671\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# step #15:  Building on the previous classifiers you defined, create two different pipelines as follows:\n",
    "#   a. Pipeline #1 : Name it pipeline1_firstname. The pipeline should have two steps, the first the transformer you prepared in step #4 and the second the Extra Trees Classifier you prepared in step 8.e.\n",
    "#   b. Pipeline #2 : Name it pipeline1_firstname. The pipeline should have two steps, the first the transformer you prepared in step #4 and the second the Decision Tree Classifier you prepared in step 8.d\n",
    "# this is the stept 4 : Prepare a standard scaler transformer to transform all the numeric values. Name the transformer transformer_firstname.\n",
    "# this is the step 8.e : Define 5 classifiers & give them names of your choice, just add at the end _X, where X is the first letter of your last name. Details of classifiers are as follows:\n",
    "# d. Decision Tree Classifier set criterion=\"entropy\" & max_depth =42\n",
    "# e. Extra Trees Classifier, use the defaults\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline1_renee = Pipeline([('scaler', transformer_renee), ('et', extra_trees_v)])\n",
    "pipeline2_renee = Pipeline([('scaler', transformer_renee), ('dt', decision_tree_v)])\n",
    "# Fit the original data to both pipelines\n",
    "pipeline1_renee.fit(X_train_renee, y_train_renee)\n",
    "pipeline2_renee.fit(X_train_renee, y_train_renee)\n",
    "# step # 17 : Carry out a 10 fold cross validation for both pipelines set shuffling to true and random_state to 42\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores_pipeline1 = cross_val_score(pipeline1_renee, X_train_renee, y_train_renee, cv=kf, scoring='accuracy', n_jobs=-1)\n",
    "scores_pipeline2 = cross_val_score(pipeline2_renee, X_train_renee, y_train_renee, cv=kf, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "\n",
    "# Printout the mean score evaluation for both pipelines, note the final results in your written response and advise which pipeline performed better\n",
    "print(scores_pipeline1.mean())\n",
    "print(scores_pipeline2.mean())\n",
    "# Predict the test using both pipelines and printout the confusion matrix, precision, recall and accuracy scores and record the results in your written response. (Use a loop)\n",
    "for pipeline in (pipeline1_renee, pipeline2_renee):\n",
    "    pipeline.fit(X_train_renee, y_train_renee)\n",
    "    y_pred = pipeline.predict(X_test_renee)\n",
    "    print(pipeline)\n",
    "    print(confusion_matrix(y_test_renee, y_pred))\n",
    "    print(classification_report(y_test_renee, y_pred))\n",
    "    print(accuracy_score(y_test_renee, y_pred))\n",
    "    print('----------------------------------')\n",
    "\n",
    "# step of 20: Compare the results and compare them against each other and against the accuracy scores you recorded during step #18, write some conclusions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Exercise #4: Extra Trees and Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10,\n",
       "                   estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;et&#x27;, ExtraTreesClassifier())]),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;et__max_depth&#x27;: array([  1,   3,   5,   7,   9,  11,  13,  15,  17,  19,  21,  23,  25,\n",
       "        27,  29,  31,  33,  35,  37,  39,  41,  43,  45,  47,  49,  51,\n",
       "        53,  55,  57,  59,  61,  63,  65,  67,  69,  71,  73,  75,  77,\n",
       "        79,  81,  83,  85,  87,  89,  91,  93,  95,  97,  99, 101, 103,\n",
       "       105, 107, 109, 111, 113, 1...\n",
       "       1550, 1570, 1590, 1610, 1630, 1650, 1670, 1690, 1710, 1730, 1750,\n",
       "       1770, 1790, 1810, 1830, 1850, 1870, 1890, 1910, 1930, 1950, 1970,\n",
       "       1990, 2010, 2030, 2050, 2070, 2090, 2110, 2130, 2150, 2170, 2190,\n",
       "       2210, 2230, 2250, 2270, 2290, 2310, 2330, 2350, 2370, 2390, 2410,\n",
       "       2430, 2450, 2470, 2490, 2510, 2530, 2550, 2570, 2590, 2610, 2630,\n",
       "       2650, 2670, 2690, 2710, 2730, 2750, 2770, 2790, 2810, 2830, 2850,\n",
       "       2870, 2890, 2910, 2930, 2950, 2970, 2990])},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=10,\n",
       "                   estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;et&#x27;, ExtraTreesClassifier())]),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;et__max_depth&#x27;: array([  1,   3,   5,   7,   9,  11,  13,  15,  17,  19,  21,  23,  25,\n",
       "        27,  29,  31,  33,  35,  37,  39,  41,  43,  45,  47,  49,  51,\n",
       "        53,  55,  57,  59,  61,  63,  65,  67,  69,  71,  73,  75,  77,\n",
       "        79,  81,  83,  85,  87,  89,  91,  93,  95,  97,  99, 101, 103,\n",
       "       105, 107, 109, 111, 113, 1...\n",
       "       1550, 1570, 1590, 1610, 1630, 1650, 1670, 1690, 1710, 1730, 1750,\n",
       "       1770, 1790, 1810, 1830, 1850, 1870, 1890, 1910, 1930, 1950, 1970,\n",
       "       1990, 2010, 2030, 2050, 2070, 2090, 2110, 2130, 2150, 2170, 2190,\n",
       "       2210, 2230, 2250, 2270, 2290, 2310, 2330, 2350, 2370, 2390, 2410,\n",
       "       2430, 2450, 2470, 2490, 2510, 2530, 2550, 2570, 2590, 2610, 2630,\n",
       "       2650, 2670, 2690, 2710, 2730, 2750, 2770, 2790, 2810, 2830, 2850,\n",
       "       2870, 2890, 2910, 2930, 2950, 2970, 2990])},\n",
       "                   random_state=42, scoring=&#x27;accuracy&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;et&#x27;, ExtraTreesClassifier())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;ExtraTreesClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html\">?<span>Documentation for ExtraTreesClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ExtraTreesClassifier()</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=10,\n",
       "                   estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                             ('et', ExtraTreesClassifier())]),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'et__max_depth': array([  1,   3,   5,   7,   9,  11,  13,  15,  17,  19,  21,  23,  25,\n",
       "        27,  29,  31,  33,  35,  37,  39,  41,  43,  45,  47,  49,  51,\n",
       "        53,  55,  57,  59,  61,  63,  65,  67,  69,  71,  73,  75,  77,\n",
       "        79,  81,  83,  85,  87,  89,  91,  93,  95,  97,  99, 101, 103,\n",
       "       105, 107, 109, 111, 113, 1...\n",
       "       1550, 1570, 1590, 1610, 1630, 1650, 1670, 1690, 1710, 1730, 1750,\n",
       "       1770, 1790, 1810, 1830, 1850, 1870, 1890, 1910, 1930, 1950, 1970,\n",
       "       1990, 2010, 2030, 2050, 2070, 2090, 2110, 2130, 2150, 2170, 2190,\n",
       "       2210, 2230, 2250, 2270, 2290, 2310, 2330, 2350, 2370, 2390, 2410,\n",
       "       2430, 2450, 2470, 2490, 2510, 2530, 2550, 2570, 2590, 2610, 2630,\n",
       "       2650, 2670, 2690, 2710, 2730, 2750, 2770, 2790, 2810, 2830, 2850,\n",
       "       2870, 2890, 2910, 2930, 2950, 2970, 2990])},\n",
       "                   random_state=42, scoring='accuracy')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carryout a randomized grid search on the first Pipeline you defined in step #15: The randomized grid search should investigate the use of different values for the following two parameters:\n",
    "# a.\tThe number of trees in the forest. Use a distribution between the values of 10 trees and 3000 trees with a step of 20.\n",
    "# b.\tThe maximum depth of the tree.  Use a distribution between the values of 1 max depth and 1000 max_depth with a step of 2.\n",
    "# Choose appropriate names for both your grid search parameter objects that end with_05.\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "n_estimators_05 = np.arange(10, 3000, 20)\n",
    "max_depth_05 = np.arange(1, 1000, 2)\n",
    "param_distributions_05 = {'et__n_estimators': n_estimators_05, 'et__max_depth': max_depth_05}\n",
    "# 22.\tFit your training data to the randomized gird search object.\n",
    "randomized_search_05 = RandomizedSearchCV(pipeline1_renee, param_distributions_05, n_iter=100, cv=10, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "randomized_search_05.fit(X_train_renee, y_train_renee)\n",
    "# 23.\tPrint out the best parameters and accuracy score for randomized grid search and record them in your written response and comment on these results. For example, compare the accuracy score to the one you obtained in step # 17 and compare the parameters suggested by the randomized grid search to the ones you used in the classifier setup i.e. step #8. list any conclusions you noticed.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[127  24]\n",
      " [ 33  47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82       151\n",
      "           1       0.66      0.59      0.62        80\n",
      "\n",
      "    accuracy                           0.75       231\n",
      "   macro avg       0.73      0.71      0.72       231\n",
      "weighted avg       0.75      0.75      0.75       231\n",
      "\n",
      "0.7532467532467533\n"
     ]
    }
   ],
   "source": [
    "# 24.\tUse the fine-tuned model identified during the randomized grid search i.e the best estimator saved in the randomized grid search object to predict the test data and note the results it in your written response.\n",
    "y_pred_05 = randomized_search_05.best_estimator_.predict(X_test_renee)\n",
    "print(confusion_matrix(y_test_renee, y_pred_05))\n",
    "print(classification_report(y_test_renee, y_pred_05))\n",
    "print(accuracy_score(y_test_renee, y_pred_05))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
